{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03H0-8BcLAA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('Snowflake/snowflake-arctic-embed-l')\n",
        "model = AutoModel.from_pretrained('Snowflake/snowflake-arctic-embed-l', add_pooling_layer=False)\n",
        "model.eval()\n",
        "\n",
        "query_prefix = 'Represent this sentence for searching relevant passages: '\n",
        "queries  = ['what is snowflake?', 'Where can I get the best tacos?']\n",
        "queries_with_prefix = [\"{}{}\".format(query_prefix, i) for i in queries]\n",
        "query_tokens = tokenizer(queries_with_prefix, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "\n",
        "documents = ['The Data Cloud!', 'Mexico City of Course!']\n",
        "document_tokens =  tokenizer(documents, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
        "\n",
        "# Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    query_embeddings = model(**query_tokens)[0][:, 0]\n",
        "    doument_embeddings = model(**document_tokens)[0][:, 0]\n",
        "\n",
        "\n",
        "# normalize embeddings\n",
        "query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
        "doument_embeddings = torch.nn.functional.normalize(doument_embeddings, p=2, dim=1)\n",
        "\n",
        "scores = torch.mm(query_embeddings, doument_embeddings.transpose(0, 1))\n",
        "for query, query_scores in zip(queries, scores):\n",
        "    doc_score_pairs = list(zip(documents, query_scores))\n",
        "    doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "    #Output passages & scores\n",
        "    print(\"Query:\", query)\n",
        "    for document, score in doc_score_pairs:\n",
        "        print(score, document)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering\n",
        "Here we're selecting the Snowflake Arctic model and giving it a prompt telling it how to customize the output. Sample response:"
      ],
      "metadata": {
        "id": "6SEZdNrfMXhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SET prompt =\n",
        "'###\n",
        "Summarize this transcript in less than 200 words.\n",
        "Put the product name, defect and summary in JSON format.\n",
        "###';\n",
        "\n",
        "select snowflake.cortex.complete('snowflake-arctic',concat('[INST]',$prompt,transcript,'[/INST]')) as summary\n",
        "from call_transcripts where language = 'English' limit 1;"
      ],
      "metadata": {
        "id": "aidL6-W7MWeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we're selecting the Snowflake Arctic model and giving it a prompt telling it how to customize the output. Sample response:"
      ],
      "metadata": {
        "id": "27mWBonLMhRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"product\": \"XtremeX helmets\",\n",
        "    \"defect\": \"broken buckles\",\n",
        "    \"summary\": \"Mountain Ski Adventures received a batch of XtremeX helmets with broken buckles. The agent apologized and offered a replacement or refund. The customer preferred a replacement, and the agent expedited a new shipment of ten helmets with functioning buckles to arrive within 3-5 business days.\"\n",
        "}"
      ],
      "metadata": {
        "id": "BLWGj7jYMbnq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}